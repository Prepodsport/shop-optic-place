# This is an example configuration file
# To learn more, see the full config.yaml reference: https://docs.continue.dev/reference

name: My model
version: 1.0.0
schema: v1

# Define which models can be used
# https://docs.continue.dev/customization/models
models:
  - name: vLLM Qwen2.5-Coder 7B (Chat/Edit/Apply)
    provider: openai
    model: qwen2.5-coder-7b
    apiBase: http://localhost:8001/v1

    roles:
      - chat
      - edit
      - apply
    capabilities: []

context:
  - provider: code
  - provider: docs
  - provider: diff
  - provider: terminal
  - provider: problems
  - provider: folder
  - provider: codebase
  - provider: tree
  - provider: repo-map
# MCP Servers that Continue can access
# https://docs.continue.dev/customization/mcp-tools

